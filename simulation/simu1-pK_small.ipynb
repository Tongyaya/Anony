{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of CPUs: 12\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "\n",
    "NUM_CPU = len(os.sched_getaffinity(0))\n",
    "print(f'Number of CPUs: {NUM_CPU}')\n",
    "NUM_THREADS = 1 \n",
    "os.environ[\"OMP_NUM_THREADS\"]     = str(NUM_THREADS)\n",
    "os.environ[\"MKL_NUM_THREADS\"]     = str(NUM_THREADS)\n",
    "os.environ[\"OPENBIAS_NUM_THREADS\"] = str(NUM_THREADS)\n",
    "os.environ[\"VECLIB_MAXIMUM_THREADS\"] = str(NUM_THREADS)\n",
    "os.environ[\"NUMEXPR_NUM_THREADS\"]  = str(NUM_THREADS)\n",
    "\n",
    "NUM_PROCESS = int(NUM_CPU // NUM_THREADS) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import time\n",
    "from copy import deepcopy\n",
    "np.set_printoptions(suppress=True)\n",
    "from multiprocessing import Pool\n",
    "\n",
    "def beta_true_gen(N,p,K,gamma):\n",
    "    '''\n",
    "    Generate beta_true\n",
    "    '''\n",
    "    np.random.seed(0)  \n",
    "    beta_true = np.zeros([p+1,K-1])\n",
    "    for k in range(K-1):\n",
    "        beta_true[:,k] = np.random.normal(size = [p+1,]) \n",
    "        beta_true[:,k] = beta_true[:,k]/np.linalg.norm(beta_true[:,k])\n",
    "    beta_true[0,:] = beta_true[0,:] + gamma*np.log(N)\n",
    "    return beta_true\n",
    "\n",
    "def X_gen(N, p=5, rho=0.5):\n",
    "    '''\n",
    "    Generate features X\n",
    "    '''\n",
    "    mean = np.zeros(p)\n",
    "    cov = np.zeros([p,p])\n",
    "    for i in range(p):\n",
    "        for j in range(i,p):\n",
    "            cov[i,j]=rho**(np.abs(i-j))\n",
    "    cov = cov+cov.T-np.eye(p)        \n",
    "    X = np.random.multivariate_normal(mean, cov, (N,)) \n",
    "    return(X)\n",
    "\n",
    "def get_onehot(y,baseclass = None):\n",
    "    '''One-hot'''\n",
    "    idx = np.squeeze(y)\n",
    "    ss = len(y)\n",
    "    nclass = len(np.unique(y))\n",
    "    z = np.zeros([ss,nclass])\n",
    "    z[np.arange(ss),idx] = 1  \n",
    "    ls_class = list(np.arange(nclass))\n",
    "    if baseclass is None:\n",
    "        baseclass = K-1\n",
    "    _ = ls_class.pop(baseclass)\n",
    "    return z[:,ls_class]\n",
    "\n",
    "def mle_multilogistic_opt_ic(x,y,K0_pval,baseclass = None): \n",
    "    '''GMLE (NR algorithm)'''\n",
    "    ss,ncov = x.shape  \n",
    "    K = len(np.unique(y))    \n",
    "    y = get_onehot(y,baseclass) \n",
    "    dist=1.0; niter=0\n",
    "    beta0 = np.zeros([ncov*(K-1),1])  \n",
    "    alpha0 = np.log((1/K0_pval-1)/(K-1)) \n",
    "    beta0[np.arange(K-1)*ncov] = alpha0 \n",
    "    while (dist>1.0e-6) & (niter<50):\n",
    "        niter=niter+1\n",
    "        beta0mat = (beta0.reshape([(K-1),ncov]).T)*1.0\n",
    "        link_mu = x@beta0mat  \n",
    "        prob = np.exp(link_mu);prob=prob/(1+np.sum(prob,axis = 1,keepdims=True))\n",
    "        resid = y-prob\n",
    "        D1=((x.T@resid/ss).T.flatten()).reshape([-1,1]) # The first-order derivative\n",
    "        Xrep = x.reshape([1,ss,ncov]) * np.ones([K-1,1,1]) \n",
    "        XMAT = (prob.T).reshape([K-1,ss,1]) * Xrep  \n",
    "        XMAT = (XMAT.transpose([1,0,2])).reshape([ss,-1])  \n",
    "        D2 = -(XMAT.T @ XMAT/ss)  # The second-order derivative\n",
    "        \n",
    "        for i in range(K-1):    \n",
    "            probtmp = (prob[:,i])*1.0\n",
    "            weight = np.sqrt(probtmp*(1-probtmp))\n",
    "            wx = weight.reshape([ss,1]) ; wx = wx * x\n",
    "            D2[i*ncov:(i+1)*ncov,i*ncov:(i+1)*ncov] = wx.T@wx/ss   \n",
    "\n",
    "        step = (np.linalg.inv(D2+1.0e-6*np.eye(ncov*(K-1))))@D1   \n",
    "        beta1 = beta0+step\n",
    "        assert beta1.shape==(ncov*(K-1),1),'shape is wrong'\n",
    "        dist = np.mean(np.abs(beta1-beta0))\n",
    "        beta0 = beta1\n",
    "    return beta0.reshape([(K-1),ncov]).T, dist, niter  \n",
    "\n",
    "def gd_multilogistic_opt_ic(x,y,K0_pval,baseclass, alpha): \n",
    "    '''GMLE (GD algorithm)'''\n",
    "    ss,ncov = x.shape  \n",
    "    K = len(np.unique(y)) \n",
    "    y = get_onehot(y,baseclass) \n",
    "    dist = 1.0; niter = 0\n",
    "    beta0 = np.zeros([ncov*(K-1),1]) \n",
    "    alpha0 = np.log((1/K0_pval-1)/(K-1))\n",
    "    beta0[np.arange(K-1)*ncov] = alpha0\n",
    "    while (dist>1.0e-6) & (niter<1000):\n",
    "        niter=niter+1\n",
    "        beta0mat = (beta0.reshape([(K-1),ncov]).T)*1.0\n",
    "        link_mu = x@beta0mat  \n",
    "        prob = np.exp(link_mu);prob=prob/(1+np.sum(prob,axis = 1,keepdims=True))\n",
    "        resid = y-prob\n",
    "        D1=((x.T@resid/ss).T).reshape([-1,1])\n",
    "        beta1 = beta0 + alpha * D1\n",
    "        assert beta1.shape==(ncov*(K-1),1),'shape is wrong'\n",
    "        dist = np.mean(np.abs(beta1-beta0))\n",
    "        beta0 = beta1\n",
    "    return beta0.reshape([(K-1),ncov]).T, dist, niter \n",
    "\n",
    "\n",
    "def mle_logistic_cpu_ic(k):\n",
    "    '''PMLE'''\n",
    "    np.random.seed(k)\n",
    "    # Subsample\n",
    "    idx_k = np.where(Y==k)[0] \n",
    "    idx_k = np.concatenate((idx_0,idx_k)) \n",
    "    x = X[idx_k]; y = Y[idx_k]\n",
    "    # Optimization\n",
    "    ss,ncov = x.shape  \n",
    "    y = y.reshape(ss,1)\n",
    "    y = 1*(y!=0) \n",
    "    dist=1.0\n",
    "    niter=0\n",
    "    beta0 = np.zeros([ncov,1])\n",
    "    alpha0 = np.log(1/K0_pval-1)\n",
    "    beta0[0] = alpha0\n",
    "    \n",
    "    while (dist>1.0e-6) & (niter<50):\n",
    "        niter=niter+1\n",
    "        link_mu = x@beta0  \n",
    "        prob = np.exp(link_mu);prob=prob/(1+prob)\n",
    "        resid=y-prob\n",
    "        D1=x.T@resid/ss  # The first-order derivative\n",
    "        weight = np.sqrt(prob*(1-prob))\n",
    "        wx  = weight*x \n",
    "        del weight\n",
    "        D2=wx.T@wx/ss+1.0e-6*np.eye(ncov)  # The second-order derivative\n",
    "        del wx \n",
    "        step=np.linalg.inv(D2)@D1\n",
    "        beta1=beta0+step\n",
    "        assert beta1.shape==(ncov,1),'shape is wrong'\n",
    "        dist=np.mean(np.abs(beta1-beta0))\n",
    "        beta0=beta1\n",
    "    return beta1.reshape([ncov,])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0: 10.65s\n",
      "\n",
      "10.6564s\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "N = 10**5, 2*10**5, 5*10**5\n",
    "'''\n",
    "N = 10**5    # Sample size\n",
    "p = 10       # Feature dimension\n",
    "K = 11       # Number of Classes\n",
    "gamma = -0.5 # Rareness\n",
    "nsimu = 100\n",
    "alpha = 40\n",
    "baseclass = 0\n",
    "K0_pval = 0.9\n",
    "a = 25\n",
    "\n",
    "t_nr = np.zeros(nsimu)\n",
    "t_gd = np.zeros(nsimu)\n",
    "t_pmle = np.zeros(nsimu)\n",
    "\n",
    "beta_hat = np.zeros([nsimu,p+1,(K-1)])\n",
    "beta_hat_nr = np.zeros([nsimu,p+1,(K-1)])\n",
    "beta_hat_gd = np.zeros([nsimu,p+1,(K-1)])\n",
    "dist = np.zeros([nsimu]); dist_nr = 0*dist; dist_gd = 0*dist\n",
    "niter = np.zeros([nsimu]);  niter_nr = 0*niter;  niter_gd = 0*niter\n",
    "num_pos_idxs = np.zeros([nsimu,K])\n",
    "\n",
    "beta_true = beta_true_gen(N,p,K,-0.5) \n",
    "\n",
    "t3 = time.time()\n",
    "for b in range(nsimu):\n",
    "    if (b % a==0): t1 = time.time()\n",
    "    \n",
    "    np.random.seed(b)\n",
    "    X = X_gen(N,p)\n",
    "    X = np.hstack([np.ones([N,1]),X]) \n",
    "\n",
    "    prob = np.exp(X@beta_true) \n",
    "    prob = np.hstack([np.ones([N,1]),prob])  \n",
    "    prob = prob/np.sum(prob,1).reshape([N,1])\n",
    "    prob = np.cumsum(prob,1)   \n",
    "    Y = (np.random.uniform(size = [N,1])<prob).astype(np.int16)\n",
    "    Y = np.argmax(Y,1) \n",
    "    idx_0 = np.where(Y==0)[0] \n",
    "    \n",
    "    cls = np.zeros([N,K])\n",
    "    cls[np.arange(N),Y] = 1 \n",
    "    num_pos_idxs[b] =  np.sum(cls,0) \n",
    "    del cls\n",
    "    \n",
    "    ## GMLE: NR\n",
    "    t5 = time.time()\n",
    "    beta_hat_nr[b], dist_nr[b], niter_nr[b] = mle_multilogistic_opt_ic(X,Y,K0_pval,baseclass = baseclass)\n",
    "    t6 = time.time(); t_nr[b] = t6-t5\n",
    "    \n",
    "    ## GMLE: GD\n",
    "    t5 = time.time()\n",
    "    beta_hat_gd[b], dist_gd[b], niter_gd[b] = gd_multilogistic_opt_ic(X,Y,K0_pval,baseclass,alpha)\n",
    "    t6 = time.time(); t_gd[b] = t6-t5\n",
    "    \n",
    "    ## PMLE: NR\n",
    "    np.random.seed(b)\n",
    "    t5 = time.time()\n",
    "    with Pool(K-1) as pool:\n",
    "        beta_hat[b] = np.array(pool.map(mle_logistic_cpu_ic, [k for k in range(1,K)])).T\n",
    "\n",
    "    t6 = time.time(); t_pmle[b] = t6-t5\n",
    "    \n",
    "    if (b % a==0): \n",
    "        t2 = time.time(); print('epoch {}: {}s'.format(b,np.round(t2-t1, 2)))\n",
    "\n",
    "t4 = time.time(); print(f'\\n{np.round(t4-t3,4)}s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.savez(f'./N{int(N/10**5)}_K{K}_p{p}_K0_pval[{K0_pval}].npz', \n",
    "#          beta_pmle=beta_hat, beta_nr=beta_hat_nr, beta_gd=beta_hat_gd, beta_true=beta_true,\n",
    "#          t_pmle = t_pmle, t_nr = t_nr,t_gd = t_gd, num_pos_idxs=num_pos_idxs,\n",
    "#          niter_pmle = niter, niter_nr = niter_nr,niter_gd = niter_gd,\n",
    "#         dist_pmle = dist, dist_nr = dist_nr,dist_gd = dist_gd)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myconda",
   "language": "python",
   "name": "myconda"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
